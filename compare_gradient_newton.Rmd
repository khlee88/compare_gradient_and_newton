---
title: "Compare Gradient And Newton Method"
output: 
 html_notebook:
        toc: true
        number_sections: true
        theme: cerulean
        highlight: tango
---

<hr>
<br>

# Overview
다음 [regression tutorial](https://khlee88.github.io/regression_tutorial/#use-optimization)에서 `optim`함수를 사용하여 $\beta$해를 구하였다. <br>
이때, 사용된 최적화 알고리즘은 'BFGS'로 newton method를 사용한다. <br>
딥러닝에서 일반적으로 사용되는 Gradient Descent방법과 어떤 차이가 있는지 Newton method는 어떻게 동작하는지 확인해 본다. <br>

뉴턴메소드의 구체적인 내용은 구글링을 통해 더 자세히 알 수 있기 때문에 생략한다. <br>
간략히는 $f(x)=0$이 되는 해(x)를 찾는 방법이고 임의의 초기값 $x_0$로 부터 $f'(x_0)=f(x_0)/\Delta$ 즉, $x_0$에서의 기울기 함수가 0이 되는 지점으로 x값을 업데이트 하는 것이다. <br>
최종적으로 다음식으로 나타낼 수 있다. $x_{n+1}=x_n - \frac{f(x_n)}{f'(x_n)}$이 된다. <br>

이제 newton method의 개념을 알았고 수식을 알았는데... Regression model에 직접 적용해 보려면 어떻게 해야할까? <br>
물론 한번에 어떻게 적용해야 하는지 아는 사람도 있겠지만, 내가 처음에 의문을 가졌던 부분들을 code로 풀어가면서 이해해 보도록 하겠다.
<br>

# First question...

* $Loss=f(x)=x(x-1)$ 
* loss function이 위와 같다면, gradient descent는 다음과 같이 10에서 출발해서 0.5에 수렴할 것이다. <br>

```{r}
g <- 10

for(i in 1:100) {
    g_1 <- g
    g <- g - 0.1*(2*g-1) ## learning rate: 0.1
    if(g_1 - g < 1e-8) break
}
print(paste0("i:", i, "  g:", g))
```

* 반면 newton method는 초기값 10에서 출발한다면, 1에 수렴할 것이다.
```{r}
n <- 10
for(i in 1:100) {
    n_1 <- n
    f <- n*(n-1)
    f_p <- 2*n - 1
    n <- n - f/f_p
    if(n_1 - n < 1e-8) break
}
print(paste0("i:", i, "  n:", n))
```

* 기계학습(리그레션, 딥러닝)에서 구하고자 하는 해는 loss가 최소가 되는 즉, 0.5이다. 그런데 왜 newton 방법은 1의 해를 찾는 것인데, 어떻게 newton 방법이 기계학습에서 적용되는 것인지 헷갈린다.

# Make Toy Dataset
$\beta$해가 0.5인 일변량 toy 데이터를 다음과 같이 만든다.
```{r}
set.seed(1050)
N <- 10
p <- 1
x <- scale(matrix(rnorm(N*p), ncol=p)) 
b <- c(0.5)
y <- x %*% b + rnorm(N, sd=.1)

plot(x, y)
abline(0,0.5)
```

# Calulate Beta 
## Using lm function
`lm` 함수를 사용해서 간단하게 $\beta$(coefficients)를 구할 수 있다.
```{r}
lr_pack <- lm(y ~ .-1, data=data.frame(X=x, y=y))
lr_pack$coefficients
```

## Using batch gradient descent
이제 다음과 같이 batch gradient descent 방법으로 해를 찾을 수 있다. <br>
해는 `lm`함수를 사용한 결과와 동일하고, 약 200회 전에 수렴하는 것으로 보인다. 
```{r}
bg <- 10  ## 초기값
bg_hist <- c()
lr = 0.05 ## 학습률
for(i in 1:1000) {
    loss <- sum( (y-bg*x)^2 ) / (2*length(y))
    gd <- sum(-x*(y - bg*x)) / length(y) 
    bg <- bg - lr*gd
    bg_hist <- c(bg_hist, bg)
}
print(bg)

plot(c(1:1000), bg_hist)
```

## Using newton method
이제 nethon method로 beta를 계산해 본다. <br>

$f(x)$를 loss function이라 하면, gradient x는 $f'(x)$가 된다. <br>
결과 beta는 0.438로 나타나고 history를 보면, 특정 값에 수렴하지 않고 0 주위로 일정하며, 중간중간 이상치 들이 발생하는 모습이다. <br>
무엇이 잘 못 된 것인가??
```{r}
bn <- 10
bn_hist <- c()
for(i in 1:1000) {
    loss <- sum( (y-bn*x)^2 ) / (2*length(y)) 
    gd <- sum(-x*(y - bn*x)) / length(y) 
    bn <- bn - loss/gd
    bn_hist <- c(bn_hist, bn)
}
print(bn)

plot(c(1:1000), bn_hist)
```

newton method에서는 f(x)를 0이 되는 점(해)을 찾는 것이고, gradient descent에서는 f(x)가 최소가 되는 점을 찾는 것이다. <br>
"first question"의 오류는 newton method와 gradient descent의 f(x)를 동일하게 생각했다는 것이다. <b>
다시, g.d는 f(x)가 최소가 되는 점을 찾기 위해 $f'(x)$가 0이 되는 점을 찾는 다. 즉, n.m는 $f'(x)$부터 시작해서 0이 되는 점을 찾는 것인데, $f'(x)$ 에서의 기울기가 필요하므로 $f''(x)$ 값이 필요하다. <br>
$Loss=f(x)$라고 한다면, n.m에서 $x_{n+1}=x_n - \frac{f'(x)}{f''(x)}$ 이 되는 것이다. <br>
다시 n.m으로 beta를 찾아보자.

```{r}
bn2 <- 10
bn2_hist <- c()
for(i in 1:1000) {
    gd <- sum(-x*(y - bn2*x)) / length(y) 
    gd2 <- sum(x^2) / length(y)    
    bn2 <- bn2 - gd / gd2
    bn2_hist <- c(bn2_hist, bn2)
}
print(bn2)

plot(c(1:1000), bn2_hist)
```

beta는 0.4626으로 lm과 g.d 방법과 동일하게 나타났다. <br>
history graph를 보면, 첫번째 시도 부터 해를 찾았고 계속 동일하게 나타난다. <br>
사실, mean squared error는 2차 식이기 때문에, $f'(x)$는 1차 식이 된다. 그리고 기울기 $f''(x)$는 상수가 된다. <br>
즉, $f'(x)$는 0을 지나는 직선이기 때문에, 어떤 점에서 시작을 해도 한번에 0인 점을 찾을 수 있는 것이다.

```{r}
bn2 <- 100
gd <- sum(-x*(y - bn2*x)) / length(y) 
gd2 <- sum(x^2) / length(y)    
bn2 <- bn2 - gd / gd2
bn2
```

## What about for the stochastic method?? 
### Gradient descent
beta값은 0.4638로 전체(batch)로 학습한 beta값과 유사하게 수렴하는 것으로 나타난다. <br>
학습 횟수는 약 6000회 이상에서 수렴하는 것으로 보이고, epoch으로는 약 600회이다. <br>
stochastic 방법이 batch 방법보다 서서히 감소하는 것을 확인할 수 있다.
```{r}
bg <- 10
bg_hist <- c()
lr = 0.001
for(i in 1:1000) {
    ### epoch마다 shuffling한다.
    #shuffle <- sample(1:10)
    #xs <- x[shuffle]
    #ys <- y[shuffle]
    for(j in 1:length(y)) {
        loss <- (y[j] - bg * x[j])^2  / 2
        gd <- -x[j] * ( y[j] - bg * x[j] )
        bg <- bg - lr*gd   
        bg_hist <- c(bg_hist, bg)
    }
}
print(bg)
plot(c(1:10000), bg_hist)
```


다음 그림은, 2700~2800 학습 구간으로 error가 증가 감소를 반복하며 서서히 낮아 지는 것으로 보인다.
```{r}
plot(c(2700:2800), bg_hist[2700:2800])
```

### Newton method
Newton method로 stochastic하게 학습한다면, beta 값은 0.397로 나타난다. <br>
history를 보면 beta 값이 수렴하는 것이 아니라, 일정한 패턴으로 반복되고 있는 것 으로 보인다. <br>
위 batch 방법에서 newton method는 한방에 beta해를 찾는다. 즉, stochastic하게 학습할 경우 다음 history와 같이 데이터 하나 하나 계속 beta값이 변하게 될 것이다. <br>
결론적으로 newton method를 사용하여 stochastic 또는 미니배치로 학습할 경우 데이터가 마지막 데이터에 피팅되기 때문에 올바른 결과를 얻기 어려울 것이다.
```{r}
bn2 <- 10
bn2_hist <- c()
for(i in 1:10) {
    #shuffle <- sample(1:10)
    #xs <- x[shuffle]
    #ys <- y[shuffle]
    for(j in 1:length(y)) {
        gd <- -x[j] *(y[j] - bn2*x[j])
        gd2 <- sum(x[j]^2)
        bn2 <- bn2 - gd / gd2
        bn2_hist <- c(bn2_hist, bn2)
    }
}
print(bn2)
plot(c(1:100), bn2_hist)
```

# Newton method for Multivariate
다 변량일 경우 newton method는 $f''(x)$를 구해야 하기 때문에 해를 구하기가 복잡해진다. <br>
예를 들어 이변량일 경우, <br>
$f(x,y)$에 대하여, $f'(x,y)=df(x,y)=\frac{\partial f}{\partial x}dx + \frac{\partial f}{\partial y}dy$ 로 나타낼 수 있다. <br>
newton method는 $f'(x,y)$가 0이 되는 해가 필요하므로 각 변수에 대한 편미분을 수행한다. <br>
$$\frac {\partial f'}{\partial x} = \frac {\partial^2 f'}{\partial x^2}dx + \frac {\partial^2 f'}{\partial x \partial y}dy$$ <br>
$$\frac {\partial f'}{\partial y} = \frac {\partial^2 f'}{\partial y \partial x}dx + \frac {\partial^2 f'}{\partial y^2}dy$$ <br>
$$=>$$ <br>
$$\left[ \begin{gathered}
  \frac {\partial f'}{\partial x} \hfill \\
  \frac {\partial f'}{\partial y} \hfill \\ 
\end{gathered}  \right] = \left[ {\begin{array}{*{20}{c}}
  {\frac {\partial^2 f'}{\partial x^2}}&{\frac {\partial^2 f'}{\partial x \partial y}} \\ 
  {\frac {\partial^2 f'}{\partial y \partial x}}&{\frac {\partial^2 f'}{\partial y^2}} 
\end{array}} \right]\left[ {\begin{array}{*{20}{c}}
  {dx} \\ 
  {dy} 
\end{array}} \right]$$

즉, 우측식 첫번째 matrix가 Hessian matrix가 된다. <br>
중간 유도 과정은 너무 복잡하여 생략하고 결과 식을 본다면, 먼저 일변량에서는 $x_{n+1}=x_n - \frac{f'(x)}{f''(x)}$ 이와같이 표현되었다. <br>
다변량에서는 $f''(x)$가 H가 됨으로, $X_{n+1} = X_n - H^{-1}f'(X_n)$ 이 된다. <br>
즉, 다변량에서는 Hessian matrix의 역행렬이 필요하게 된다. 그러므로 변수(d)가 많을 수록 H가 $d\times d$로 커지게 됨으로 연산량이 매우 커지게 된다. <br>

# Conclusion

Newton Method를 기계학습관점에서 Gradient Descent와 비교하며 code로 동작 원리를 확인하였다. <br>
확인한 사실을 요약하면 다음과 같다.

* G.D는 $Loss=f(x)$의 최소가 되는 점을 조금씩 찾아 가는 것이고 N.M은 $f'(x)$가 0이 되는 해를 찾아 가는 것이다.
    * 결국 목적은 같지만, 시작점과 방법에 차이가 있다.
* G.D는 점진적으로 해를 찾아가기 때문에 learning rate라는 설정 파라미터가 필요하고 그에 따라 수렴속도의 차이를 가진다. <br>
N.M은 설정 파라미터가 필요 없고 빠른 수렴속도를 가진다.
* G.D는 Mini-batch를 사용하여 학습 효율을 높일 수 있지만, N.M은 마지막 데이터에 피팅이 되므로 사용하기 어렵다.
* 다변량의 경우 G.D는 변수 만큼의 편미분 계산이 필요하지만, N.M은 변수의 제곱만큼 계산이 필요하므로 그리고 역함수를 계산해야 하므로 변수가 많이 질 수록 연산량이 매우 높아지게 된다.

기존 빅데이터-딥러닝에서 주로 G.D가 사용되는 것이 이러한 N.M의 약점 때문이라고 생각된다.

<br><br><br><br><br>